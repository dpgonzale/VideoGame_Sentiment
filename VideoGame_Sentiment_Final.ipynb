{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "from tflearn.data_utils import to_categorical, pad_sequences, VocabularyProcessor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "score_phrase    0\n",
       "title           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data and drop unneeded columns\n",
    "dataset = pd.read_csv('ign.csv').iloc[:, 1:3]  #import relevelant columns from dataset\n",
    "dataset.fillna(value='', inplace=True)         #replance any blank or nan data with empty string\n",
    "#print(dataset.columns)\n",
    "\n",
    "# Check for null or missing data\n",
    "dataset.isnull().sum()\n",
    "\n",
    "# Fill in or create missing data\n",
    "# dataframe.fillna(value='', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  LittleBigPlanet PS Vita\n",
       "1        LittleBigPlanet PS Vita -- Marvel Super Hero E...\n",
       "2                                     Splice: Tree of Life\n",
       "3                                                   NHL 13\n",
       "4                                                   NHL 13\n",
       "5                                Total War Battles: Shogun\n",
       "6                                      Double Dragon: Neon\n",
       "7                                             Guild Wars 2\n",
       "8                                      Double Dragon: Neon\n",
       "9                                Total War Battles: Shogun\n",
       "10                                 Tekken Tag Tournament 2\n",
       "11                                 Tekken Tag Tournament 2\n",
       "12                                              Wild Blood\n",
       "13                                       Mark of the Ninja\n",
       "14                                       Mark of the Ninja\n",
       "15                         Home: A Unique Horror Adventure\n",
       "16                         Home: A Unique Horror Adventure\n",
       "17                                     Avengers Initiative\n",
       "18                                    Way of the Samurai 4\n",
       "19                             JoJo's Bizarre Adventure HD\n",
       "20                             JoJo's Bizarre Adventure HD\n",
       "21                                Mass Effect 3: Leviathan\n",
       "22                                Mass Effect 3: Leviathan\n",
       "23                                Mass Effect 3: Leviathan\n",
       "24                     Dark Souls (Prepare to Die Edition)\n",
       "25                                                Symphony\n",
       "26                                                 Bastion\n",
       "27                       Tom Clancy's Ghost Recon Phantoms\n",
       "28                                Thirty Flights of Loving\n",
       "29                                               Legasista\n",
       "                               ...                        \n",
       "18595                                         Ghostbusters\n",
       "18596                                           Necropolis\n",
       "18597                                        7 Days to Die\n",
       "18598                                                 Furi\n",
       "18599                                           Pokemon Go\n",
       "18600                                    Hitman: Episode 4\n",
       "18601                                    Hitman: Episode 4\n",
       "18602                                    Hitman: Episode 4\n",
       "18603                                              Grow Up\n",
       "18604                                        Madden NFL 17\n",
       "18605                                         No Man's Sky\n",
       "18606      Starcraft II: Nova Covert Ops -- Mission Pack 2\n",
       "18607                                           Pokemon Go\n",
       "18608                              Carmageddon: Max Damage\n",
       "18609                           Monster Hunter Generations\n",
       "18610                                     Song of the Deep\n",
       "18611             Tom Clancy's The Division -- Underground\n",
       "18612                                           BoxBoxBoy!\n",
       "18613                             XCOM 2: Shen's Last Gift\n",
       "18614                                    Zero Time Dilemma\n",
       "18615                                    Zero Time Dilemma\n",
       "18616    Batman: The Telltale Series -- Episode 1: Real...\n",
       "18617                                                 Abzu\n",
       "18618                                            Starbound\n",
       "18619                                      Human Fall Flat\n",
       "18620                            Tokyo Mirage Sessions #FE\n",
       "18621                    LEGO Star Wars: The Force Awakens\n",
       "18622              Star Ocean: Integrity and Faithlessness\n",
       "18623                                               Inside\n",
       "18624                                               Inside\n",
       "Name: title, Length: 18625, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract independent & dependent variables (X & Y)\n",
    "trainX = dataset.title\n",
    "trainY = dataset.score_phrase\n",
    "trainX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Amazing\n",
       "1            Amazing\n",
       "2              Great\n",
       "3              Great\n",
       "4              Great\n",
       "5               Good\n",
       "6              Awful\n",
       "7            Amazing\n",
       "8              Awful\n",
       "9               Good\n",
       "10              Good\n",
       "11              Good\n",
       "12              Good\n",
       "13           Amazing\n",
       "14           Amazing\n",
       "15              Okay\n",
       "16              Okay\n",
       "17             Great\n",
       "18          Mediocre\n",
       "19              Good\n",
       "20              Good\n",
       "21              Good\n",
       "22              Good\n",
       "23              Good\n",
       "24           Amazing\n",
       "25              Good\n",
       "26           Amazing\n",
       "27              Good\n",
       "28             Great\n",
       "29              Okay\n",
       "            ...     \n",
       "18595            Bad\n",
       "18596           Okay\n",
       "18597            Bad\n",
       "18598           Okay\n",
       "18599           Good\n",
       "18600           Good\n",
       "18601           Good\n",
       "18602           Good\n",
       "18603           Good\n",
       "18604          Great\n",
       "18605           Okay\n",
       "18606           Okay\n",
       "18607           Good\n",
       "18608       Mediocre\n",
       "18609          Great\n",
       "18610           Okay\n",
       "18611       Mediocre\n",
       "18612           Good\n",
       "18613          Great\n",
       "18614        Amazing\n",
       "18615        Amazing\n",
       "18616           Good\n",
       "18617          Great\n",
       "18618        Amazing\n",
       "18619           Good\n",
       "18620           Good\n",
       "18621        Amazing\n",
       "18622       Mediocre\n",
       "18623    Masterpiece\n",
       "18624    Masterpiece\n",
       "Name: score_phrase, Length: 18625, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1259, 3428, 2741, ...,    0,    0,    0],\n",
       "       [1259, 3428, 2741, ...,    0,    0,    0],\n",
       "       [4734, 1718,    3, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  11,  883, 8145, ...,    0,    0,    0],\n",
       "       [ 843,    0,    0, ...,    0,    0,    0],\n",
       "       [ 843,    0,    0, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert sequence data (strings) into numeric data\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=\"<UNK>\")\n",
    "tokenizer.fit_on_texts(trainX)\n",
    "x = tokenizer.texts_to_sequences(trainX)\n",
    "\n",
    "# Convert data into a matrix array and pad with zeros\n",
    "totalX = tf.keras.preprocessing.sequence.pad_sequences(x, maxlen=15, padding='post', truncating='post')\n",
    "totalX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5],\n",
       "       [ 5],\n",
       "       [ 1],\n",
       "       ...,\n",
       "       [ 4],\n",
       "       [10],\n",
       "       [10]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert sequence data (strings) into numeric data\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(trainY)\n",
    "Y = tokenizer.texts_to_sequences(trainY)\n",
    "#print(Y.count([11]))\n",
    "\n",
    "# Convert data into a matrix array\n",
    "totalY = np.array(Y)\n",
    "totalY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the indices into 11 dimensional vectors\n",
    "tocatY =  to_categorical(totalY, nb_classes=12) \n",
    "# Drop first column of zeros\n",
    "totalY = np.delete(tocatY, 0, 1)\n",
    "totalY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\gonzo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tflearn\\layers\\recurrent.py:69: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From c:\\users\\gonzo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tflearn\\layers\\recurrent.py:681: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From c:\\users\\gonzo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From c:\\users\\gonzo\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Split data into training, test and validation\n",
    "trainX, testX, trainY, testY = train_test_split(totalX, totalY, test_size=0.1)\n",
    "\n",
    "# Build Model\n",
    "net = tflearn.input_data([None, trainX.shape[1]])\n",
    "net = tflearn.embedding(net, input_dim=10000, output_dim=128)\n",
    "net = tflearn.lstm(net, 128, dropout=0.9)\n",
    "#net = tflearn.lstm(net, 128, dropout=0.6)\n",
    "net = tflearn.fully_connected(net, 11, activation='softmax') # relu or softmax\n",
    "net = tflearn.regression(net, optimizer='adam', learning_rate=.0001, loss='categorical_crossentropy')\n",
    "#model = tflearn.DNN(net, tensorboard_verbose=0, checkpoint_path='SavedModels/model.tfl.ckpt')\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 16799  | total loss: \u001b[1m\u001b[32m26.37685\u001b[0m\u001b[0m | time: 10.508s\n",
      "| Adam | epoch: 100 | loss: 26.37685 - acc: 0.0573 -- iter: 16700/16762\n",
      "Training Step: 16800  | total loss: \u001b[1m\u001b[32m26.37685\u001b[0m\u001b[0m | time: 11.572s\n",
      "| Adam | epoch: 100 | loss: 26.37685 - acc: 0.0516 | val_loss: 26.37685 - val_acc: 0.0338 -- iter: 16762/16762\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(trainX, trainY, validation_set=(testX, testY), show_metric=True, batch_size=100, n_epoch=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
